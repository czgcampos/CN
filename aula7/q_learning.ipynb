{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://deeplearningcourses.com/c/artificial-intelligence-reinforcement-learning-in-python\n",
    "# https://www.udemy.com/artificial-intelligence-reinforcement-learning-in-python\n",
    "from __future__ import print_function, division\n",
    "from builtins import range\n",
    "# Note: you may need to update your version of future\n",
    "# sudo pip install -U future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from grid_world import standard_grid, negative_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.9\n",
    "ALPHA = 0.1\n",
    "ALL_POSSIBLE_ACTIONS = ('U', 'D', 'L', 'R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_action(a, eps=0.1):\n",
    "\t# we'll use epsilon-soft to ensure all states are visited\n",
    "\t# what happens if you don't do this? i.e. eps=0\n",
    "\tp = np.random.random()\n",
    "\tif p < (1 - eps):\n",
    "\t\treturn a\n",
    "\telse:\n",
    "\t\treturn np.random.choice(ALL_POSSIBLE_ACTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_dict(d):\n",
    "\t# returns the argmax (key) and max (value) from a dictionary\n",
    "\t# put this into a function since we are using it so often\n",
    "\tmax_key = None\n",
    "\tmax_val = float('-inf')\n",
    "\tfor k, v in d.items():\n",
    "\t\tif v > max_val:\n",
    "\t\t\tmax_val = v\n",
    "\t\t\tmax_key = k\n",
    "\treturn max_key, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_values(V, g):\n",
    "\tfor i in range(g.rows):\n",
    "\t\tprint(\"---------------------------\")\n",
    "\t\tfor j in range(g.cols):\n",
    "\t\t\tv = V.get((i,j), 0)\n",
    "\t\t\tif v >= 0:\n",
    "\t\t\t\tprint(\" %.2f|\" % v, end=\"\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"%.2f|\" % v, end=\"\") # -ve sign takes up an extra space\n",
    "\t\tprint(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_policy(P, g):\n",
    "\tfor i in range(g.rows):\n",
    "\t\tprint(\"---------------------------\")\n",
    "\t\tfor j in range(g.cols):\n",
    "\t\t\ta = P.get((i,j), ' ')\n",
    "\t\t\tprint(\"  %s  |\" % a, end=\"\")\n",
    "\t\tprint(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10| 1.00|\n",
      "---------------------------\n",
      "-0.10| 0.00|-0.10|-1.00|\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10|-0.10|\n",
      "it: 0\n",
      "it: 2000\n",
      "it: 4000\n",
      "it: 6000\n",
      "it: 8000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update counts:\n",
      "---------------------------\n",
      " 0.03| 0.04| 0.16| 0.00|\n",
      "---------------------------\n",
      " 0.02| 0.00| 0.17| 0.00|\n",
      "---------------------------\n",
      " 0.19| 0.19| 0.18| 0.02|\n",
      "values:\n",
      "---------------------------\n",
      " 0.62| 0.80| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.46| 0.00| 0.80| 0.00|\n",
      "---------------------------\n",
      " 0.31| 0.46| 0.62| 0.46|\n",
      "policy:\n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  U  |     |  U  |     |\n",
      "---------------------------\n",
      "  R  |  R  |  U  |  L  |\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  # NOTE: if we use the standard grid, there's a good chance we will end up with\n",
    "  # suboptimal policies\n",
    "  # e.g.\n",
    "  # ---------------------------\n",
    "  #   R  |   R  |   R  |      |\n",
    "  # ---------------------------\n",
    "  #   R* |      |   U  |      |\n",
    "  # ---------------------------\n",
    "  #   U  |   R  |   U  |   L  |\n",
    "  # since going R at (1,0) (shown with a *) incurs no cost, it's OK to keep doing that.\n",
    "  # we'll either end up staying in the same spot, or back to the start (2,0), at which\n",
    "  # point we whould then just go back up, or at (0,0), at which point we can continue\n",
    "  # on right.\n",
    "  # instead, let's penalize each movement so the agent will find a shorter route.\n",
    "  #\n",
    "  # grid = standard_grid()\n",
    "  grid = negative_grid(step_cost=-0.1)\n",
    "\n",
    "  # print rewards\n",
    "  print(\"rewards:\")\n",
    "  print_values(grid.rewards, grid)\n",
    "\n",
    "  # no policy initialization, we will derive our policy from most recent Q\n",
    "\n",
    "  # initialize Q(s,a)\n",
    "  Q = {}\n",
    "  states = grid.all_states()\n",
    "  for s in states:\n",
    "    Q[s] = {}\n",
    "    for a in ALL_POSSIBLE_ACTIONS:\n",
    "      Q[s][a] = 0\n",
    "\n",
    "  # let's also keep track of how many times Q[s] has been updated\n",
    "  update_counts = {}\n",
    "  update_counts_sa = {}\n",
    "  for s in states:\n",
    "    update_counts_sa[s] = {}\n",
    "    for a in ALL_POSSIBLE_ACTIONS:\n",
    "      update_counts_sa[s][a] = 1.0\n",
    "\n",
    "  # repeat until convergence\n",
    "  t = 1.0\n",
    "  deltas = []\n",
    "  for it in range(10000):\n",
    "    if it % 100 == 0:\n",
    "      t += 1e-2\n",
    "    if it % 2000 == 0:\n",
    "      print(\"it:\", it)\n",
    "\n",
    "    # instead of 'generating' an episode, we will PLAY\n",
    "    # an episode within this loop\n",
    "    s = (2, 0) # start state\n",
    "    grid.set_state(s)\n",
    "\n",
    "    # the first (s, r) tuple is the state we start in and 0\n",
    "    # (since we don't get a reward) for simply starting the game\n",
    "    # the last (s, r) tuple is the terminal state and the final reward\n",
    "    # the value for the terminal state is by definition 0, so we don't\n",
    "    # care about updating it.\n",
    "    a, _ = max_dict(Q[s])\n",
    "    biggest_change = 0\n",
    "    while not grid.game_over():\n",
    "\t\n",
    "      a = random_action(a, eps=0.5/t) # epsilon-greedy\n",
    "      # random action also works, but slower since you can bump into walls\n",
    "      # a = np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "      r = grid.move(a)\n",
    "      s2 = grid.current_state()\n",
    "\n",
    "      # adaptive learning rate\n",
    "      alpha = ALPHA / update_counts_sa[s][a]\n",
    "      update_counts_sa[s][a] += 0.005\n",
    "\n",
    "      # we will update Q(s,a) AS we experience the episode\n",
    "      old_qsa = Q[s][a]\n",
    "      # the difference between SARSA and Q-Learning is with Q-Learning\n",
    "      # we will use this max[a']{ Q(s',a')} in our update\n",
    "      # even if we do not end up taking this action in the next step\n",
    "      a2, max_q_s2a2 = max_dict(Q[s2])\n",
    "      Q[s][a] = Q[s][a] + alpha*(r + GAMMA*max_q_s2a2 - Q[s][a])\n",
    "      biggest_change = max(biggest_change, np.abs(old_qsa - Q[s][a]))\n",
    "\n",
    "      # we would like to know how often Q(s) has been updated too\n",
    "      update_counts[s] = update_counts.get(s,0) + 1\n",
    "\n",
    "      # next state becomes current state\n",
    "      s = s2\n",
    "      a = a2\n",
    "     \n",
    "    deltas.append(biggest_change)\n",
    "\n",
    "  plt.plot(deltas)\n",
    "  plt.show()\n",
    "\n",
    "  # determine the policy from Q*\n",
    "  # find V* from Q*\n",
    "  policy = {}\n",
    "  V = {}\n",
    "  for s in grid.actions.keys():\n",
    "    a, max_q = max_dict(Q[s])\n",
    "    policy[s] = a\n",
    "    V[s] = max_q\n",
    "\n",
    "  # what's the proportion of time we spend updating each part of Q?\n",
    "  print(\"update counts:\")\n",
    "  total = np.sum(list(update_counts.values()))\n",
    "  for k, v in update_counts.items():\n",
    "    update_counts[k] = float(v) / total\n",
    "  print_values(update_counts, grid)\n",
    "\n",
    "  print(\"values:\")\n",
    "  print_values(V, grid)\n",
    "  print(\"policy:\")\n",
    "  print_policy(policy, grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
